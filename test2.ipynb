{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onomaai/anaconda3/envs/brian/lib/python3.10/site-packages/datasets/load.py:926: FutureWarning: The repository for wmt14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at wmt14/wmt14.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, inspect_dataset, load_dataset_builder, VerificationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onomaai/anaconda3/envs/brian/lib/python3.10/site-packages/datasets/load.py:926: FutureWarning: The repository for wmt_utils contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at ./wmt14/wmt_utils.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "builder = load_dataset_builder(\n",
    "    './wmt14/wmt_utils.py',\n",
    "    language_pair = ('fr', 'en'),\n",
    "    subsets = {\n",
    "        datasets.Split.TRAIN: [\"europarl_v7\", \"newscommentary_v10\"],\n",
    "        datasets.Split.VALIDATION: ['newstest2013'],\n",
    "        datasets.Split.TEST: ['newstest2014']\n",
    "    },\n",
    "    cache_dir = '/data2/brian/.cache/dataset'\n",
    ")\n",
    "# datasets.DatasetBuilder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 658M/658M [00:57<00:00, 11.5MB/s]   \n",
      "Downloading data: 100%|██████████| 125M/125M [00:11<00:00, 10.6MB/s] \n",
      "Downloading data: 100%|██████████| 38.7M/38.7M [00:03<00:00, 11.9MB/s]\n",
      "Generating train split:   5%|▌         | 2201939/40836715 [00:40<11:46, 54656.88 examples/s]\n",
      "Generating validation split: 100%|██████████| 3000/3000 [00:00<00:00, 51898.78 examples/s]\n",
      "Generating test split: 100%|██████████| 3003/3003 [00:00<00:00, 41986.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "builder.download_and_prepare(verification_mode=VerificationMode.NO_CHECKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = builder.as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2201939\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 3003\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
